
# Name your project! Project names should contain only lowercase characters
# and underscores. A good package name should reflect your organization's
# name or the intended use of these models
name: 'ei_loader_dbt'
version: '1.0.0'
config-version: 2

# This setting configures which "profile" dbt uses for this project.
profile: 'ei_loader_dbt'

# These configurations specify where dbt should look for different types of files.
# The `model-paths` config, for example, states that models in this project can be
# found in the "models/" directory. You probably won't need to change these!
model-paths: ["models"]
analysis-paths: ["analyses"]
test-paths: ["tests"]
seed-paths: ["seeds"]
macro-paths: ["macros","sds_readonly_macros"]
snapshot-paths: ["snapshots"]

target-path: "target"  # directory which will store compiled SQL files
clean-targets:         # directories to be removed by `dbt clean`
  - "target"
  - "dbt_packages"

vars:
  start_epoch: -779979582
  end_epoch: -700000000
  skew_factor: 100


# Configuring models
# Full documentation: https://docs.getdbt.com/docs/configuring-models

# In this example config, we tell dbt to build all models in the example/
# directory as views. These settings can be overridden in the individual model
# files using the `{{ config(...) }}` macro.
models:
  ei_loader_dbt:
    +pre-hook:
      - SET spark.shuffle.io.maxRetries = 4;
      - SET spark.sql.parser.quotedRegexColumnNames = true;
      - SET `spark.sql.iceberg.merge-schema` = true;
    # Config indicated by + and applies to all files under models/example/
    example:
      +materialized: view
      +on_table_exists: drop
      +on_schema_change: append_new_columns
      +incremental_strategy: insert_overwrite
